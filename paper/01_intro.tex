\section{Introduction}
\label{sec:intro}
Even in the modern era, mathematical work is often done by hand. However, modern technology requires digital typesetting for ease of reading. \LaTeX\ is a typesetting system used to display mathematical equations, but is tedious to work with and impractical for jotting down rapid thoughts. Despite these drawbacks, all substantial math research must be translated to \LaTeX\ before publishing. Due to the prevalence of \LaTeX\ in the scientific world, it would be beneficial to have a system for recognizing \LaTeX\ from images and text. As such, the goal of this project is to utilize ML techniques to convert hand drawn images of mathematical expressions directly into its \LaTeX\ markup sequence. In addition, this project eliminates the need for pen and paper, allowing the user to hand-write equations "virtually" by using a webcam. While others have tackled subsets of this problem with various results\cite{Peng2021, Genthial2016, Wang2019, Wang2021}, to our knowledge, none have implemented a full app pipeline that works with handwritten equations.


Thanks to major advances in computer vision techniques within the past decade, numerous models have been developed that are highly accurate in detecting text within images. However, successfully translating an entire hand written mathematical expression into its corresponding \LaTeX\ code sequence remains a formidable challenge. This is due to the fact that in addition to correctly determining each symbol, one must also consider the spatial arrangement of each symbol relative to the others. To this end, our model utilizes and encoder-decoder transformer model equipped with positional encoding in order to store spatial relationships between symbols. 

% The model was trained and tested against the CROHME dataset and achieved perfect scores on up to 24\% of test inputs and less than 10 errors (scored by the Levenshtein distance) on up to 90\% of test inputs on CROHME 2019.

